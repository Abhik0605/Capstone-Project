{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Capstone Project\n",
    "\n",
    "\n",
    "## Purpose\n",
    "The purpose of this project is to explore the venues of Toronto and Waterloo and understand the differences between a big city and a smaller city.\n",
    "\n",
    "## Background\n",
    "Predicting where to open a business is a very hard problem. The number of variables that go into solving this kind of problem is a lot. It is almost impossible to predict whether a certain kind of business might succeed in one neighbourhood vs the other, one city vs the other, Evironment, culture, people, religion, time, location, asthetic appeal they all intermingle with each other to predict whether a certain place might be a good place for a business. Also what kind of business also makes a big difference. I am no expert and neither do I claim to be I just experiment and analyze and predict. So I just go into this problem blindly and see what comes out of the end. In this project I look into one variable which is the venue data on othere people's busineses and I cluster them and see which cluster is good for which kind of business.\n",
    "\n",
    "\n",
    "## Methodology\n",
    "I. Data acquisiton and cleaning\n",
    "\n",
    "II. Data Analysis\n",
    "\n",
    "III. Clustering\n",
    "\n",
    "IV. Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Library import\n",
    "We import all the required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported all the neccesary libraries \n",
    "from bs4 import BeautifulSoup # For Web Scraping\n",
    "\n",
    "import csv\n",
    "import pandas as pd #Data Analysis\n",
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy as np\n",
    "\n",
    "import geocoder #get location data\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import requests\n",
    "import json #To handle json files\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from sklearn.cluster import KMeans # To run k-means algorithm\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors # matplotlib stuff\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline # backend for rendering plots wit\n",
    "\n",
    "import folium # To visualize on map\n",
    "from folium.map import *\n",
    "from folium import plugins\n",
    "from folium.plugins import MeasureControl\n",
    "from folium.plugins import FloatImage\n",
    "\n",
    "import json\n",
    "\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "print('Libraries Imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve all the required data for the analysis. I use the arcgis API to get the required Waterloo-Kitchener Neighbourhood Data. I am aware that these Neighbourhoods might not be accurate in their location but these are just rough placeholder names to segment the area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Waterloo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://services.arcgis.com/ZpeBVw5o1kjit7LT/arcgis/rest/services/NeighbourhoodAssociations/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json'\n",
    "data = requests.get(url).json()  \n",
    "\n",
    "\n",
    "with open('data.geojson', 'w') as json_file:\n",
    "    json.dump(data, json_file)\n",
    "\n",
    "address = 'Waterloo, Ontario, Canada'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"waterloo_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Waterloo City are {}, {}.'.format(latitude, longitude))\n",
    "\n",
    "element = []\n",
    "\n",
    "for item in data['features']:\n",
    "    i = round(len(item['geometry']['rings'][0])/2)+round(len(item['geometry']['rings'][0])/3)\n",
    "    element.append([item['attributes']['NAME'],item['attributes']['TYPE'],item['geometry']['rings'][0][i][1],item['geometry']['rings'][0][i][0]])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(element,columns = ['Neighbourhood', 'Neighbourhood Type','lat','long'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Kitchener Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://services1.arcgis.com/qAo1OsXi67t7XgmS/arcgis/rest/services/Neighbourhood_Association/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json'\n",
    "\n",
    "data2 = requests.get(url).json() \n",
    "\n",
    "data2['features'][0]\n",
    "\n",
    "element = []\n",
    "\n",
    "for item in data2['features']:\n",
    "    i = round(len(item['geometry']['rings'][0])/5)\n",
    "    element.append([item['attributes']['MAPLABEL1'],item['attributes']['NEIGHBOURHOOD_ASSOCIATION'],item['geometry']['rings'][0][i][1],item['geometry']['rings'][0][i][0]])\n",
    "    \n",
    "element[:5]\n",
    "\n",
    "df2 = pd.DataFrame(element,columns = ['Neighbourhood', 'Neighbourhood Type','lat','long'])\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining them to get the bigger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big = pd.concat([df,df2],axis = 0,sort = False).reset_index()\n",
    "\n",
    "df_big.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting venue data from this DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df_big['Neighbourhood']\n",
    "latitudes = df_big['lat']\n",
    "longtitudes = df_big['long']\n",
    "radius = 500\n",
    "\n",
    "CLIENT_ID = 'JR0WCEE3K2VYBHOHIRHCAPOL3BXLGM2WHQNPCXXJ0GB20HPP' #Foursquare ID\n",
    "CLIENT_SECRET = '251PHKQSNFRZEAMTRWB3YKHYRHT50WRVAAW35AMS3CHXDFE2' # Foursquare Secret\n",
    "VERSION = '20200528' # Foursquare API version\n",
    "LIMIT = 500\n",
    "\n",
    "list = []\n",
    "\n",
    "\n",
    "for name,lat,long in zip(names,latitudes,longtitudes):\n",
    "    url = f'https://api.foursquare.com/v2/venues/explore?&client_id={CLIENT_ID}&client_secret={CLIENT_SECRET}&v={VERSION}&ll={lat},{long}&radius={radius}&limit={LIMIT}'\n",
    "    json = requests.get(url).json()\n",
    "#     venues = json['response']['groups'][0]['items']\n",
    "    try:\n",
    "        venues = json['response']['groups'][0]['items']\n",
    "        list.append([(\n",
    "                    name,\n",
    "                    lat,\n",
    "                    long,\n",
    "                    v['venue']['name'], \n",
    "                    v['venue']['location']['lat'],\n",
    "                    v['venue']['categories'][0]['name'],\n",
    "                    v['venue']['location']['lng']) for v in venues]\n",
    "                   )\n",
    "    except:\n",
    "        continue\n",
    "missing_values = []\n",
    "for name,lat,long in zip(names,latitudes,longtitudes):\n",
    "    url = f'https://api.foursquare.com/v2/venues/explore?&client_id={CLIENT_ID}&client_secret={CLIENT_SECRET}&v={VERSION}&ll={lat},{long}&radius={radius}&limit={LIMIT}'\n",
    "    try:\n",
    "        json = requests.get(url).json()\n",
    "        venues = json['response']['groups'][0]['items']\n",
    "        if len(venues) == 0:\n",
    "            missing_values.append(name)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values # The neighbourhoods which have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in missing_values:  \n",
    "    df_big = df_big[df_big['Neighbourhood'] != item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_stuff = pd.DataFrame([item for venue_list in list for item in venue_list],columns = ['Neighbourhood','lat','long','venue','venue lat','venue type','venue long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_stuff.to_csv(r'C:\\Users\\Abhik\\Downloads\\venue_waterloo_data.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_stuff.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Toronto data from previous analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_venue_data = pd.read_csv('venue_toronto_data.csv')\n",
    "toronto_venue_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_clusters = pd.read_csv('toronto_clusters.csv')\n",
    "toronto_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our desired DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KW_map = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "\n",
    "for lat,lng,neighbourhood in zip(df_big['lat'],df_big['long'],df_big['Neighbourhood Type']):\n",
    "    label = f'{neighbourhood}'\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat,lng],\n",
    "        radius = 5,\n",
    "        popup=label,\n",
    "        color = 'green',\n",
    "        fill = True,\n",
    "        parse_html=False, \n",
    "    ).add_to(KW_map)\n",
    "    \n",
    "\n",
    "KW_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "venue_stuff = pd.read_csv('venue_waterloo_data.csv')\n",
    "waterloo_onehot = pd.get_dummies(venue_stuff[['venue type']],prefix ='',prefix_sep = '')\n",
    "waterloo_onehot['Neighbourhood'] = venue_stuff['Neighbourhood']\n",
    "\n",
    "fixed_columns = [waterloo_onehot.columns[-1]] + waterloo_onehot.columns[:-1].to_list()\n",
    "\n",
    "waterloo_onehot = waterloo_onehot[fixed_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterloo_grouped = waterloo_onehot.groupby('Neighbourhood').mean().reset_index()\n",
    "waterloo_grouped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterloo_clustered = waterloo_grouped.drop('Neighbourhood',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kclusters = 15\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(waterloo_clustered)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big.insert(0, 'Cluster Labels', kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia=[]\n",
    "N = 55\n",
    "K = []\n",
    "for k in range(2,N) :\n",
    "    K.append(k)\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(waterloo_clustered)\n",
    "    inertia.append(kmeans.inertia_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(df_big['lat'], df_big['long'], df_big['Neighbourhood'], df_big['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "\n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(kclusters):\n",
    "    print(f'cluster {i}')\n",
    "    venue_cluster = df_big[df_big['Cluster Labels'] == i]\n",
    "    for item in venue_cluster['Neighbourhood']:        \n",
    "        display(venue_stuff[venue_stuff['Neighbourhood'] == item].drop('Neighbourhood',1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'Toronto, Ontario, Canada'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"yyz_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "kclusters = 30\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(toronto_clusters['lat'], toronto_clusters['long'], toronto_clusters['Borough'], toronto_clusters['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "\n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to attach each cluster label to its respective venue and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = []\n",
    "for j in range(len(toronto_clusters['Cluster Labels'])):\n",
    "    cluster_i_neighbourhood = toronto_clusters[toronto_clusters['Cluster Labels'] == j].reset_index()['Borough'].to_list()\n",
    "    for i in range(len(cluster_i_neighbourhood)):\n",
    "        cluster_list = np.full(shape=len(toronto_venue_data[toronto_venue_data['Borough']==cluster_i_neighbourhood[i]]),\n",
    "                           fill_value=j).tolist()\n",
    "        temp = toronto_venue_data[toronto_venue_data['Borough']==cluster_i_neighbourhood[i]]\n",
    "        temp.insert(0,'Cluster Labels',cluster_list)\n",
    "        dataframe.append(temp)\n",
    "\n",
    "venue_cluster = pd.concat(dataframe[i] for i in range(len(toronto_clusters['Cluster Labels']))).reset_index(drop=True)\n",
    "venue_cluster.drop_duplicates().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'Toronto, Ontario, Canada'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"yyz_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "\n",
    "map_clusters = folium.Map(location=[latitude, longitude],tiles='Stamen Toner', zoom_start=11)\n",
    "\n",
    "kclusters = 30\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(len(toronto_clusters['Cluster Labels']))]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(venue_cluster['venue lat'], venue_cluster['venue long'], venue_cluster['Borough'], venue_cluster['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=1,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "\n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = []\n",
    "for j in range(len(df_big['Cluster Labels'])):\n",
    "    cluster_i_neighbourhood = df_big[df_big['Cluster Labels'] == j].reset_index()['Neighbourhood'].to_list()\n",
    "    for i in range(len(cluster_i_neighbourhood)):\n",
    "        cluster_list = np.full(shape=len(venue_stuff[venue_stuff['Neighbourhood']==cluster_i_neighbourhood[i]]),\n",
    "                           fill_value=i).tolist()\n",
    "        temp = venue_stuff[venue_stuff['Neighbourhood']==cluster_i_neighbourhood[i]]\n",
    "        temp.insert(0,'Cluster Labels',cluster_list)\n",
    "        dataframe.append(temp)\n",
    "        \n",
    "waterloo_new_venue = pd.concat(dataframe).reset_index(drop = True)\n",
    "\n",
    "address = 'Waterloo, Ontario, Canada'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"waterloo_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "\n",
    "\n",
    "map_clusters = folium.Map(location=[latitude, longitude],tiles = 'Stamen Toner', zoom_start=13)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(waterloo_new_venue['venue lat'], waterloo_new_venue['venue long'], waterloo_new_venue['Neighbourhood'], waterloo_new_venue['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=2,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "\n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have clustered the neighbourhoods based on venue type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_6 = venue_cluster[venue_cluster['Cluster Labels']==6]\n",
    "cluster_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_6['venue type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = []\n",
    "random2 = []\n",
    "for i in range(kclusters):\n",
    "    #print(f'cluster {i}')\n",
    "    cluster_i = venue_cluster[venue_cluster['Cluster Labels']==i]\n",
    "    random.append([cluster_i['venue type'].value_counts().index[0:9].to_list(),cluster_i['Borough'].unique()])\n",
    "\n",
    "for j in range(len(waterloo_new_venue['Cluster Labels'].unique())):\n",
    "    cluster_j = waterloo_new_venue[waterloo_new_venue['Cluster Labels'] == j]\n",
    "    random2.append([cluster_j['venue type'].value_counts().index[0:9].to_list(),cluster_j['Neighbourhood'].unique()])\n",
    "\n",
    "\n",
    "#     display(cluster_i['venue type'].value_counts().index[0:9])\n",
    "#     display(cluster_i['Borough'].unique())\n",
    "#     for item in venue_cluster['Neighbourhood']:        \n",
    "#         display(venue_stuff[venue_stuff['Neighbourhood'] == item].drop('Neighbourhood',1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "f = []\n",
    "for i in pd.DataFrame(random,columns=['venue type','Borough']).iterrows():\n",
    "    d.append(i[1][0])\n",
    "    f.append(i[1][1])\n",
    "\n",
    "columns = []\n",
    "for ind in range(9):\n",
    "    columns.append(f'{ind+1}th most common venue type')\n",
    "    \n",
    "toronto_final = pd.DataFrame(d, columns = columns).reset_index(drop = True)\n",
    "toronto_cluster_neighbourhoods  = pd.DataFrame(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "f = []\n",
    "for i in pd.DataFrame(random2,columns=['venue type','Neighbourhood']).iterrows():\n",
    "    d.append(i[1][0])\n",
    "    f.append(i[1][1])\n",
    "\n",
    "columns = []\n",
    "for ind in range(9):\n",
    "    columns.append(f'{ind+1}th most common venue type')\n",
    "    \n",
    "waterloo_final = pd.DataFrame(d, columns = columns).reset_index(drop = True)\n",
    "waterloo_cluster_neighbourhoods  = pd.DataFrame(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(waterloo_final.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(toronto_final.iloc[6,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(toronto_cluster_neighbourhoods.iloc[6,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(waterloo_cluster_neighbourhoods.iloc[0,:]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
